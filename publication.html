<!DOCTYPE html>
<!-- This site was created in Webflow. https://www.webflow.com -->
<!-- Last Published: Thu May 16 2024 13:02:21 GMT+0000 (Coordinated Universal Time) -->
<html data-wf-domain="superior-space-template.webflow.io" data-wf-page="66324ca3963cb173dcf869b5" data-wf-site="66324ca3963cb173dcf869c8" lang="en">
    <head>
        <meta charset="utf-8"/>
        <title>AIM3 Lab | Publication</title>
        <meta property="og:type" content="website"/>
        <meta content="summary_large_image" name="twitter:card"/>
        <meta content="width=device-width, initial-scale=1" name="viewport"/>
        <meta content="Webflow" name="generator"/>
        <link href="webflow.css" rel="stylesheet" type="text/css"/>
        <link href="https://fonts.googleapis.com" rel="preconnect"/>
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin="anonymous"/>
        <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
        <script type="text/javascript">
            WebFont.load({
                google: {
                    families: ["Inter:100,200,300,regular,500,600,700,800,900", "Lora:regular,500,600,700,italic,500italic,600italic,700italic"]
                }
            });
        </script>
        <script type="text/javascript">
            !function(o, c) {
                var n = c.documentElement
                  , t = " w-mod-";
                n.className += t + "js",
                ("ontouchstart"in o || o.DocumentTouch && c instanceof DocumentTouch) && (n.className += t + "touch")
            }(window, document);
        </script>
        <link href="assets/logo/aim3-logo.png" rel="shortcut icon" type="image/x-icon"/>
        <link href="assets/logo/aim3-logo.png" rel="apple-touch-icon"/>
        <meta name="robots" content="noindex">
        <script type="text/javascript">
            window.__WEBFLOW_CURRENCY_SETTINGS = {
                "currencyCode": "USD",
                "symbol": "$",
                "decimal": ".",
                "fractionDigits": 2,
                "group": ",",
                "template": "{{wf {\"path\":\"symbol\",\"type\":\"PlainText\"} }} {{wf {\"path\":\"amount\",\"type\":\"CommercePrice\"} }} {{wf {\"path\":\"currencyCode\",\"type\":\"PlainText\"} }}",
                "hideDecimalForWholeNumbers": false
            };
        </script>
    </head>
    <body>
        <div class="navbar-wrap">
            <div data-animation="default" class="navbar w-nav" data-easing2="ease-in-back" data-easing="ease-out-back" data-collapse="medium" data-w-id="73651ff8-98c3-8929-4e48-aad88f43e916" role="banner" data-duration="400" data-doc-height="1">
                <div class="nav-container">
                    <div class="nav-left">
                        <div class="brand-menu-wrap">
                            <a href="/" class="brand-link w-nav-brand">
                                <img loading="lazy" src="assets/logo/aim3-logo-all-black.png" alt="" class="brand-navbar"/>
                            </a>
                        </div>
                    </div>
                    <input type="checkbox" id="menu-toggle" class="menu-toggle-checkbox">
                    <label for="menu-toggle" class="menu-toggle-label">
                        <div class="hamburger-icon">
                            <span style="background-color: black;"></span>
                            <span style="background-color: black;"></span>
                            <span style="background-color: black;"></span>
                        </div>
                    </label>
                    <nav role="navigation" class="nav-menu w-nav-menu">
                        <a href="index.html" class="nav-link w-nav-link">Home</a>
                        <a href="research.html" class="nav-link w-nav-link">Research</a>
                        <a href="publication.html" aria-current="page" class="nav-link w-nav-link w--current">Publication</a>
                        <a href="people.html" class="nav-link w-nav-link">People</a>
                        <a href="contact.html" class="nav-link w-nav-link">Contact</a>
                    </nav>
                </div>
            </div>
            <div class="nav-bg"></div>
        </div>
        <div class="section template-hero">
            <div class="main-container w-container">
                <div class="template-hero-title-wrap">
                    <h1 class="template-hero-title">Publications</h1>
                </div>
            </div>
        </div>
        <div class="section template-details">
            <div class="main-container w-container">
                <div class="columns-template-details w-row">
                    <div class="left-column-template-details w-col w-col-2">
                        <div class="card-template-navigation">
                            <a href="#2024" class="link-template-navigation">2024</a>
                            <a href="#2023" class="link-template-navigation">2023</a>
                            <a href="#2022" class="link-template-navigation">2022</a>
                            <a href="#Earlier" class="link-template-navigation">Earlier</a>
                        </div>
                    </div>
                    <div class="right-column-template-details w-col w-col-10">
                        <div id="2024" class="card-template-details">
                            <h3 class="template-h2">2024</h3><br>
                            <ul>
                                <li class="paper-list">
                                    <div class="paper-title">Tinychart: Efficient chart understanding with visual token merging and program-of-thoughts learning</div>
                                    <div class="paper-author">Liang Zhang, Anwen Hu, Haiyang Xu, Ming Yan, Yichen Xu, Qin Jin, Ji Zhang, Fei Huang</div>
                                    <div class="paper-conf">EMNLP 2024</div>
                                </li>
                                <li class="paper-list">
                                    <div class="paper-title">Revealing Personality Traits: A New Benchmark Dataset for Explainable Personality Recognition on Dialogues</div>
                                    <div class="paper-author">Lei Sun, Jinming Zhao, Qin Jin</div>
                                    <div class="paper-conf">EMNLP 2024</div>
                                </li>
                                <li class="paper-list">
                                    <div class="paper-title">Reversed in Time: A Novel Temporal-Emphasized Benchmark for Cross-Modal Video-Text Retrieval</div>
                                    <div class="paper-author">Yang Du, Yuqi Liu, Qin Jin</div>
                                    <div class="paper-conf">ACM MM 2024</div>
                                </li>
                                <li class="paper-list">
                                    <div class="paper-title">Edit As You Wish: Video Caption Editing with Multi-grained User Control</div>
                                    <div class="paper-author">Linli Yao, Yuanmeng Zhang, Ziheng Wang, Xinglin Hou, Tiezheng Ge, Yuning Jiang, Xu Sun, Qin Jin</div>
                                    <div class="paper-conf">ACM MM 2024</div>
                                </li>
                                <li class="paper-list">
                                    <div class="paper-title">SingOMD: Singing Oriented Multi-resolution Discrete Representation Construction from Speech Models</div>
                                    <div class="paper-author">Yuxun Tang, Yuning Wu, Jiatong Shi, Qin Jin</div>
                                    <div class="paper-conf">Interspeech 2024</div>
                                </li>
                                <li class="paper-list">
                                    <div class="paper-title">TokSing: Singing Voice Synthesis based on Discrete Tokens</div>
                                    <div class="paper-author">Yuning Wu, Chunlei zhang, Jiatong Shi, Yuxun Tang, Shan Yang, Qin Jin</div>
                                    <div class="paper-conf">Interspeech 2024</div>
                                </li>
                                <li class="paper-list">
                                    <div class="paper-title">Singing Voice Data Scaling-up: An Introduction to ACE-Opencpop and ACE-KiSing</div>
                                    <div class="paper-author">Jiatong Shi, Yueqian Lin, Xinyi Bai, Keyi Zhang, Yuning Wu, Yuxun Tang, Yifeng Yu, Qin Jin, Shinji Watanabe</div>
                                    <div class="paper-conf">Interspeech 2024</div>
                                </li>
                                <li class="paper-list">
                                    <div class="paper-title">The Interspeech 2024 Challenge on Speech Processing Using Discrete Units</div>
                                    <div class="paper-author">Xuankai Chang，Jiatong Shi，Jinchuan Tian，Yuning Wu，Yuxun Tang，Yihan Wu，Shinji Watanabe，Yossi Adi，Xie Chen，Qin Jin</div>
                                    <div class="paper-conf">Interspeech 2024</div>
                                </li>
                                <li class="paper-list">
                                    <div class="paper-title">Less is More: Mitigating Multimodal Hallucination from an EOS Decision Perspective</div>
                                    <div class="paper-author">Zihao Yue, Liang Zhang, Qin Jin</div>
                                    <div class="paper-conf">ACL 2024</div>
                                </li>
                                <li class="paper-list">
                                    <div class="paper-title">Synchronized Video Storytelling: Generating Video Narrations with Structured Storyline</div>
                                    <div class="paper-author">Dingyi Yang, Chunru Zhan, Ziheng Wang, Biao Wang, Tiezheng Ge, Bo Zheng, Qin Jin</div>
                                    <div class="paper-conf">ACL 2024</div>
                                </li>
                                <li class="paper-list">
                                    <div class="paper-title">ESCoT: Towards Interpretable Emotional Support Dialogue Systems</div>
                                    <div class="paper-author">Tenggan Zhang, Xinjie Zhang, Jinming Zhao, Li Zhou, Qin Jin</div>
                                    <div class="paper-conf">ACL 2024</div>
                                </li>
                                <li class="paper-list">
                                    <div class="paper-title">Respond in my Language: Mitigating Language Inconsistency in Response Generation based on Large Language Models</div>
                                    <div class="paper-author">Liang Zhang, Qin Jin, Haoyang Huang, Dongdong Zhang, Furu Wei</div>
                                    <div class="paper-conf">ACL 2024</div>
                                </li>
                                <li class="paper-list">
                                    <div class="paper-title">ECR-Chain: Advancing Generative Language Models to Better Emotion-Cause Reasoners through Reasoning Chains</div>
                                    <div class="paper-author">Zhaopei Huang, Jinming Zhao, Qin Jin</div>
                                    <div class="paper-conf">IJCAI 2024</div>
                                </li>
                                <li class="paper-list">
                                    <div class="paper-title">Adaptive Temporal Motion Guided Graph Convolution Network for Micro-expression Recognition</div>
                                    <div class="paper-author">Fengyuan Zhang, Xinjie Zhang, Zhaopei Huang, Qin Jin</div>
                                    <div class="paper-conf">ICME 2024</div>
                                </li>
                                <li class="paper-list">
                                    <div class="paper-title">UBiSS: A Unified Framework for Bimodal Semantic Summarization of Videos</div>
                                    <div class="paper-author">Yuting Mei, Linli Yao, Qin Jin</div>
                                    <div class="paper-conf">ICMR 2024</div>
                                </li>
                            </ul>
                        </div>
                        <div id="2023" class="card-template-details">
                            <h3 class="template-h2">2023</h3><br>
                            <ul>
                                <li class="paper-list">
                                    <div class="paper-title">Learning Descriptive Image Captioning via Semipermeable Maximum Likelihood Estimation</div>
                                    <div class="paper-author">Zihao Yue, Anwen Hu, Liang Zhang, Qin Jin</div>
                                    <div class="paper-conf">NeurIPS 2023</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Explore and Tell: Embodied Visual Captioning in 3D Environments</div>
                                    <div class="paper-author">Anwen Hu, Shizhe Chen, Liang Zhang, Qin Jin</div>
                                    <div class="paper-conf">ICCV 2023</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Prompt-Oriented View-agnostic Learning for Egocentric Hand-Object Interaction in the Multi-view World</div>
                                    <div class="paper-author">Boshen Xu, Sipeng Zheng, Qin Jin</div>
                                    <div class="paper-conf">ACM MM 2023</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Visual Captioning at Will: Describing Images and Videos Guided by a Few Stylized Sentences</div>
                                    <div class="paper-author">Dingyi Yang, Hongyu Chen, Xinglin Hou, Tiezheng Ge, Yuning Jiang, Qin Jin</div>
                                    <div class="paper-conf">ACM MM 2023</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Emotionally Situated Text-to-Speech Synthesis in User-Agent Conversation</div>
                                    <div class="paper-author">Yuchen Liu, Haoyu Zhang, Shichao Liu, Xiang Yin, Zejun Ma, Qin Jin</div>
                                    <div class="paper-conf">ACM MM 2023</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">InfoMetIC: An Informative Metric for Reference-free Image Caption Evaluation</div>
                                    <div class="paper-author">Anwen Hu, Shizhe Chen, Liang Zhang, Qin Jin</div>
                                    <div class="paper-conf">ACL 2023</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">UniLG: A Unified Structure-aware Framework for Lyrics Generation</div>
                                    <div class="paper-author">Tao Qian, Zhong Tian, Jiatong Shi, Yuning Wu, Shuan Guo, Xiang Yin, Qin Jin</div>
                                    <div class="paper-conf">ACL 2023</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Attractive Storyteller: Stylized Visual Storytelling with Unpaired Text</div>
                                    <div class="paper-author">Dingyi Yang, Qin Jin</div>
                                    <div class="paper-conf">ACL 2023</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Movie101: A New Movie Understanding Benchmark</div>
                                    <div class="paper-author">Zihao Yue, Qi Zhang, Anwen Hu, Liang Zhang, Ziheng Wang, Qin Jin</div>
                                    <div class="paper-conf">ACL 2023</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Rethinking Benchmarks for Cross-modal Image-Text Retrieval</div>
                                    <div class="paper-author">Weijing Chen, Linli Yao, Qin Jin</div>
                                    <div class="paper-conf">SIGIR 2023</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Knowledge Enhanced Model for Live Video Comment Generation</div>
                                    <div class="paper-author">Jieting Chen, Junkai Ding, Wenping Chen, Qin Jin</div>
                                    <div class="paper-conf">ICME 2023</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Open-Category Human-Object Interaction Pre-training via Language Modeling Framework</div>
                                    <div class="paper-author">Sipeng Zheng, Boshen Xu, Qin Jin</div>
                                    <div class="paper-conf">CVPR 2023</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">MM-Diffusion: Learning Multi-Modal Diffusion Models for Joint Audio and Video Generation</div>
                                    <div class="paper-author">Ludan Ruan, Yiyang Ma, Huan Yang, Huiguo He, Bei Liu, Nicholas Jing Yuan, Qin Jin, Jianlong Fu, Baining Guo</div>
                                    <div class="paper-conf">CVPR 2023</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">CapEnrich: Enriching Caption Semantics for Web Images via Cross-modal Pre-trained Knowledge</div>
                                    <div class="paper-author">Linli Yao, Weijing Chen, Qin Jin</div>
                                    <div class="paper-conf">WWW 2023</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">PHONEIX: Acoustic Feature Processing Strategy for Enhanced Singing Pronunciation with Phoneme Distribution Predictor</div>
                                    <div class="paper-author">Yuning Wu, Jiatong Shi, Tao Qian, Dongji Gao, Qin Jin</div>
                                    <div class="paper-conf">ICASSP 2023</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Token Mixing: Parameter-Efficient Transfer Learning from Image-Language to Video-Language</div>
                                    <div class="paper-author">Yuqi Liu, Luhui Xu, Pengfei Xiong, Qin Jin</div>
                                    <div class="paper-conf">AAAI 2023</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Accommodating Audio Modality in CLIP for Multimodal Processing</div>
                                    <div class="paper-author">Ludan Ruan, Anwen Hu, Yuqing Song, Liang Zhang, Sipeng Zheng, Qin Jin</div>
                                    <div class="paper-conf">AAAI 2023</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">MPMQA: Multimodal Question Answering on Product Manuals</div>
                                    <div class="paper-author">Liang Zhang, Anwen Hu, Jing Zhang, Shuo Hu, Qin Jin</div>
                                    <div class="paper-conf">AAAI 2023</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Multi-Modal Knowledge Hypergraph for Diverse Image Retrieval</div>
                                    <div class="paper-author">Yawen Zeng, Qin Jin, Tengfei Bao, Wenfeng Li</div>
                                    <div class="paper-conf">AAAI 2023</div>
                                </li>
                            </ul>
                        </div>
                        <div id="2022" class="card-template-details">
                            <h3 class="template-h2">2022</h3><br>
                            <ul>
                                <li class="paper-list">
                                    <div class="paper-title">Multi-Lingual Acquisition on Multimodal Pre-training for Cross-modal Retrieval</div>
                                    <div class="paper-author">Liang Zhang, Anwen Hu, Qin Jin</div>
                                    <div class="paper-conf">NeurIPS 2022</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">DialogueEIN: Emotion Interaction Network for Dialogue Affective Analysis</div>
                                    <div class="paper-author">Yuchen Liu, Jinming Zhao, Jingwen Hu, Ruichen Li, Qin Jin</div>
                                    <div class="paper-conf">COLING 2022</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">TS2-Net: Token Shift and Selection Transformer for Text-Video Retrieval</div>
                                    <div class="paper-author">Yuqi Liu, Pengfei Xiong, Luhui Xu, Shengming Cao, Qin Jin</div>
                                    <div class="paper-conf">ECCV 2022</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Few-shot Action Recognition with Hierarchical Matching and Contrastive Learning</div>
                                    <div class="paper-author">Sipeng Zheng, Shizhe Chen, Qin Jin</div>
                                    <div class="paper-conf">ECCV 2022</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Unifying Event Detection and Captioning as Sequence Generation via Pre-Training</div>
                                    <div class="paper-author">Qi Zhang, Yuqing Song, Qin Jin</div>
                                    <div class="paper-conf">ECCV 2022</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Progressive Learning for Image Retrieval with Hybrid-Modality Queries</div>
                                    <div class="paper-author">Yida Zhao, Yuqing Song, Qin Jin</div>
                                    <div class="paper-conf">SIGIR 2022</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">VRDFormer: End-to-End Video Visual Relation Detection with Transformers</div>
                                    <div class="paper-author">Sipeng Zheng, Shizhe Chen, Qin Jin</div>
                                    <div class="paper-conf">CVPR 2022</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">M3ED: Multi-modal Multi-scene Multi-label Emotional Dialogue Database</div>
                                    <div class="paper-author">Jinming Zhao, Tenggan Zhang, Jingwen Hu, Yuchen Liu, Qin Jin, Xinchao Wang, Haizhou Li</div>
                                    <div class="paper-conf">ACL 2022</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Image Difference Captioning with Pre-Training and Contrastive Learning</div>
                                    <div class="paper-author">Linli Yao, Weiying Wang, Qin Jin</div>
                                    <div class="paper-conf">AAAI 2022</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Training strategies for automatic song writing: a unified framework perspective</div>
                                    <div class="paper-author">Tao Qian, Jiatong Shi, Shuai Guo, Peter Wu, Qin Jin</div>
                                    <div class="paper-conf">ICASSP 2022</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">MEmoBERT: Pre-training Model with Prompt-based Learning for Multimodal Emotion Recognition</div>
                                    <div class="paper-author">Jinming Zhao, Ruichen Li, Qin Jin, Xinchao Wang, Haizhou Li</div>
                                    <div class="paper-conf">ICASSP 2022</div>
                                </li>
                            </ul>
                        </div>
                        <div id="Earlier" class="card-template-details">
                            <h3 class="template-h2">Earlier</h3><br>
                            <ul>
                                <li class="paper-list">
                                    <div class="paper-title">Product-oriented Machine Translation with Cross-modal Cross-lingual Pre-training</div>
                                    <div class="paper-author">Yuqing Song, Shizhe Chen, Qin Jin, Wei Luo, Jun Xie, and Fei Huang</div>
                                    <div class="paper-conf">ACM MM 2021</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Question-controlled Text-aware Image Captioning</div>
                                    <div class="paper-author">Anwen Hu, Shizhe Chen, Qin Jin</div>
                                    <div class="paper-conf">ACM MM 2021</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Enhancing Neural Machine Translation with Dual-Side Multimodal Awareness</div>
                                    <div class="paper-author">Yuqing Song, Shizhe Chen, Qin Jin, Wei Luo, Jun Xie, and Fei Huang</div>
                                    <div class="paper-conf">IEEE Transactions on Multimedia 2021</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Speech Emotion Recognition via Multi-Level Cross-Modal Distillation</div>
                                    <div class="paper-author">Ruichen Li, Jinming Zhao, Qin Jin</div>
                                    <div class="paper-conf">Interspeech 2021</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Missing Modality Imagination Network for Emotion Recognition with Uncertain Missing Modalities</div>
                                    <div class="paper-author">Jinming Zhao, Ruichen Li, Qin Jin</div>
                                    <div class="paper-conf">ACL 2021</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">MMGCN: Multimodal Fusion via Deep Graph Convolution Network for Emotion Recognition in Conversation</div>
                                    <div class="paper-author">Jingwen Hu, Yuchen Liu, Jinming Zhao, Qin Jin</div>
                                    <div class="paper-conf">ACL 2021</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Towards Diverse Paragraph Captioning for Untrimmed Videos</div>
                                    <div class="paper-author">Yuqing Song, Shizhe Chen, Qin Jin</div>
                                    <div class="paper-conf">CVPR 2021</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Sequence-To-Sequence Singing Voice Synthesis With Perceptual Entropy Loss</div>
                                    <div class="paper-author">Jiatong Shi, Shuai Guo, Nan Huo, Yuekai Zhang, Qin Jin</div>
                                    <div class="paper-conf">ICASSP 2021</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Context-aware Goodness of Pronunciation for Computer-Assisted Pronunciation Trainings</div>
                                    <div class="paper-author">Jiatong Shi, Nan Huo, Qin Jin</div>
                                    <div class="paper-conf">Interspeech 2020</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">VideoIC: A Video Interactive Comments Dataset and Multimodal Multitask Learning for Comments Generations</div>
                                    <div class="paper-author">Weiying Wang, Jieting Chen, Qin Jin</div>
                                    <div class="paper-conf">ACM MM 2020</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">ICECAP: Information Concentrated Entity-aware Image Captioning</div>
                                    <div class="paper-author">Anwen Hu, Shizhe Chen, Qin Jin</div>
                                    <div class="paper-conf">ACM MM 2020</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Semi-supervised Multi-modal Emotion Recognition with Cross-Modal Distribution Matching</div>
                                    <div class="paper-author">Jingjun Liang, Ruichen Li, Qin Jin</div>
                                    <div class="paper-conf">ACM MM 2020</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Say As You Wish: Fine-Grained Control of Image Caption Generation With Abstract Scene Graphs</div>
                                    <div class="paper-author">Shizhe Chen, Qin Jin, Peng Wang, Qi Wu</div>
                                    <div class="paper-conf">CVPR 2020</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Fine-Grained Video-Text Retrieval With Hierarchical Graph Reasoning</div>
                                    <div class="paper-author">Shizhe Chen, Yida Zhao, Qin Jin, Qi Wu</div>
                                    <div class="paper-conf">CVPR 2020</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Better Captioning With Sequence-Level Exploration</div>
                                    <div class="paper-author">Jia Chen, Qin Jin</div>
                                    <div class="paper-conf">CVPR 2020</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Skeleton-based Interactive Graph Network for Human Object Interaction Detection</div>
                                    <div class="paper-author">Sipeng Zheng, Shizhe Chen, Qin Jin</div>
                                    <div class="paper-conf">ICME 2020</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Unsupervised Bilingual Lexicon Induction from Mono-lingual Multimodal Data</div>
                                    <div class="paper-author">Shizhe Chen, Qin Jin, Alexandar Hauptmann</div>
                                    <div class="paper-conf">AAAI 2019</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Cross-culture Multimodal Emotion Recognition with Adversarial Learning</div>
                                    <div class="paper-author">Jingjun Liang, Shizhe Chen, Jinming Zhao, Qin Jin, Haibo Liu, Li Lu</div>
                                    <div class="paper-conf">ICASSP 2019</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Activitynet 2019 Task 3: Exploring Contexts for Dense Captioning Events in Video</div>
                                    <div class="paper-author">Shizhe Chen, Yuqing Song, Yida Zhao, Qin Jin, Zhaoyang Zeng, Bei Liu, Jianlong Fu, Alexander Hauptmann</div>
                                    <div class="paper-conf">CVPR 2019 ActivityNet Large Scale Activity Recognition Challenge</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">From Words to Sentences: A Progressive Learning Approach for Zero-resource Machine Translation with Visual Pivots</div>
                                    <div class="paper-author">Shizhe Chen, Qin Jin, Jianlong Fu</div>
                                    <div class="paper-conf">IJCAI 2019</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Generating Video Descriptions With Latent Topic Guidance</div>
                                    <div class="paper-author">Shizhe Chen, Qin Jin, Jia Chen, Alexander G. Hauptmann</div>
                                    <div class="paper-conf">IEEE Transactions on Multimedia 2019</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Speech Emotion Recognition in Dyadic Dialogues</div>
                                    <div class="paper-author">Jinming Zhao, Shizhe Chen, Jingjun Liang, Qin Jin</div>
                                    <div class="paper-conf">Interspeech 2019</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Unpaired Cross-lingual Image Caption Generation with Self-Supervised Rewards</div>
                                    <div class="paper-author">Yuqing Song, Shizhe Chen, Qin Jin</div>
                                    <div class="paper-conf">ACM MM 2019</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Visual Relation Detection with Multi-Level Attention</div>
                                    <div class="paper-author">Sipeng Zheng, Shizhe Chen, Qin Jin</div>
                                    <div class="paper-conf">ACM MM 2019</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Neural Storyboard Artist: Visualizing Stories with Coherent Image Sequences</div>
                                    <div class="paper-author">Shizhe Chen, Bei Liu, Jianlong Fu, Ruihua Song, Qin Jin, Pingping Lin, Xiaoyu Qi, Chunting Wang, Jin Zhou</div>
                                    <div class="paper-conf">ACM MM 2019</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Relation Understanding in Videos</div>
                                    <div class="paper-author">Sipeng Zheng, Xiangyu Chen, Shizhe Chen, Qin Jin</div>
                                    <div class="paper-conf">ACM MM Grand Challenge: Relation Understanding in Videos 2019</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Adversarial Domain Adaption for Multi-Cultural Dimensional Emotion Recognition in Dyadic Interactions</div>
                                    <div class="paper-author">Jinming Zhao, Ruichen Li, Jingjun Liang, Qin Jin</div>
                                    <div class="paper-conf">AVEC 2019</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Integrating Temporal and Spatial Attentions for VATEX Video Captioning Challenge 2019</div>
                                    <div class="paper-author">Shizhe Chen, Yida Zhao, Yuqing Song, Qin Jin, Qi Wu</div>
                                    <div class="paper-conf">ICCV VATEX Video Captioning Challenge 2019</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">YouMakeup: A Large-Scale Domain-Specific Multimodal Dataset for Fine-Grained Semantic Comprehension</div>
                                    <div class="paper-author">Weiying Wang, Yongcheng Wang, Shizhe Chen, Qin Jin</div>
                                    <div class="paper-conf">EMNLP 2019</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">RUC_AIM3 at TRECVID 2019: Video to Text</div>
                                    <div class="paper-author">Yuqing Song, Yida Zhao, Shizhe Chen, Qin Jin</div>
                                    <div class="paper-conf">NIST TRECVID 2019</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Semi-supervised Multimodal Emotion Recognition With Improved Wasserstein GANs</div>
                                    <div class="paper-author">Jingjun Liang, Shizhe Chen, Qin Jin</div>
                                    <div class="paper-conf">APSIPA ASC 2019</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">RUC+CMU: System Report for Dense Captioning Events in Videos</div>
                                    <div class="paper-author">Shizhe Chen, Yuqing Song, Yida Zhao, Qin Jin, Alexandar Hauptmann</div>
                                    <div class="paper-conf">CVPR ActivityNet Large Scale Activity Recognition Challenge 2018</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Class-aware Self-Attention for Audio Event Recognition</div>
                                    <div class="paper-author">Shizhe Chen, Jia Chen, Qin Jin, Alexandar Hauptmann</div>
                                    <div class="paper-conf">ICMR 2018 (Best Paper Runner-up)</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Multimodal Dimensional and Continuous Emotion Recognition in Dyadic Video Interactions</div>
                                    <div class="paper-author">Jinming Zhao, Shizhe Chen, Qin Jin</div>
                                    <div class="paper-conf">Pacific-Rim Conference on Multimedia (PCM) 2018</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">iMakeup: Makeup Instructional Video Dataset for Fine-grained Dense Video Captioning</div>
                                    <div class="paper-author">Xiaozhu Lin, Qin Jin, Shizhe Chen, Yuqing Song, Yida Zhao</div>
                                    <div class="paper-conf">Pacific-Rim Conference on Multimedia (PCM) 2018</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Multi-modal Multi-cultural Dimensional Continues Emotion Recognition in Dyadic Interactions</div>
                                    <div class="paper-author">Jinming Zhao, Ruichen Li, Shizhe Chen, Qin Jin</div>
                                    <div class="paper-conf">ACM MM Audio-Visual Emotion Challenge (AVEC) Workshop 2018</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Video Captioning with Guidance of Multimodal Latent Topics</div>
                                    <div class="paper-author">Shizhe Chen, Jia Chen, Qin Jin, Alexandar Hauptmann</div>
                                    <div class="paper-conf">ACM MM 2017</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Knowing Yourself: Improving Video Caption via In-depth Recap</div>
                                    <div class="paper-author">Qin Jin, Shizhe Chen, Jia Chen, Alexandar Hauptmann</div>
                                    <div class="paper-conf">ACM MM 2017 (Best Grand Challenge Paper)</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Multimodal Multi-task Learning for Dimensional and Continuous Emotion Recognition</div>
                                    <div class="paper-author">Shizhe Chen, Qin Jin, Jinming Zhao, Shuai Wang</div>
                                    <div class="paper-conf">ACM MM Audio-Visual Emotion Challenge (AVEC) Workshop 2017</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Generating Video Descriptions with Topic Guidance</div>
                                    <div class="paper-author">Shizhe Chen, Jia Chen, Qin Jin</div>
                                    <div class="paper-conf">ICMR 2017</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Emotion Recognition with Multimodal Features and Temporal Models</div>
                                    <div class="paper-author">Shuai Wang, Wenxuan Wang, Jinming Zhao, Shizhe Chen, Qin Jin, Shilei Zhang, Yong Qin</div>
                                    <div class="paper-conf">ICMI 2017</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Facial Action Units Detection with Multi-Features and-AUs Fusion</div>
                                    <div class="paper-author">Xinrui Li, Shizhe Chen, Qin Jin</div>
                                    <div class="paper-conf">Automatic Face & Gesture Recognition (FGR) 2017</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Boosting Recommendation in Unexplored Categories by User Price Preference</div>
                                    <div class="paper-author">Jia Chen, Qin Jin, Shiwan Zhao, Shenghua Bao, Li Zhang, Zhong Su, Yong Yu</div>
                                    <div class="paper-conf">ACM Transactions on Information Systems (TOIS) 2016</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Video Emotion Recognition in the Wild Based on Fusion of Multimodal Features</div>
                                    <div class="paper-author">Shizhe Chen, Xinrui Li, Qin Jin, Shilei Zhang, Yong Qin</div>
                                    <div class="paper-conf">ICMI 2016</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Describing Videos using Multi-modal Fusion</div>
                                    <div class="paper-author">Qin Jin, Jia Chen, Shizhe Chen, Yifan Xiong</div>
                                    <div class="paper-conf">ACM MM 2016</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Semantic Image Profiling for Historic Events: Linking Images to Phrases</div>
                                    <div class="paper-author">Jia Chen, Qin Jin, Yifan Xiong</div>
                                    <div class="paper-conf">ACM MM 2016</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Multi-modal Conditional Attention Fusion for Dimensional Emotion Prediction</div>
                                    <div class="paper-author">Shizhe Chen, Qin Jin</div>
                                    <div class="paper-conf">ACM MM 2016</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">History Rhyme: Searching Historic Events by Multimedia Knowledge</div>
                                    <div class="paper-author">Yifan Xiong, Jia Chen, Qin Jin, Chao Zhang</div>
                                    <div class="paper-conf">ACM MM 2016</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Detecting Violence in Video using Subclasses</div>
                                    <div class="paper-author">Xirong Li, Yujia Huo, Qin Jin, Jieping Xu</div>
                                    <div class="paper-conf">ACM MM 2016</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Generating Natural Video Descriptions via Multimodal Processing</div>
                                    <div class="paper-author">Qin Jin, Junwei Liang, Xiaozhu Lin</div>
                                    <div class="paper-conf">Interspeech 2016</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Improving Image Captioning by Concept-based Sentence Reranking</div>
                                    <div class="paper-author">Xirong Li, Qin Jin</div>
                                    <div class="paper-conf">Pacific-Rim Conference on Multimedia (PCM) 2016 (Best Paper Runner-up)</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Video Description Generation using Audio and Visual Cues</div>
                                    <div class="paper-author">Qin Jin, Junwei Liang</div>
                                    <div class="paper-conf">ICMR 2016</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Exploitation and Exploration Balanced Hierarchical Summary for Landmark Images</div>
                                    <div class="paper-author">Jia Chen, Qin Jin, Shenghua Bao, Junfeng Ye, Zhong Su, Shimin Chen, Yong Yu</div>
                                    <div class="paper-conf">IEEE Transactions on Multimedia 2015</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Lead Curve Detection in Drawings with Complex Cross-Points</div>
                                    <div class="paper-author">Jia Chen, Min Li, Qin Jin, Yongzhe Zhang, Shenghua Bao, Zhong Su, Yong Yu</div>
                                    <div class="paper-conf">Neurocomputing 2015</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Image Profiling for History Events on the Fly</div>
                                    <div class="paper-author">Jia Chen, Qin Jin, Yong Yu, Alexander G. Hauptmann</div>
                                    <div class="paper-conf">ACM MM 2015</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Persistent B+-Trees in Non-Volatile Main Memory</div>
                                    <div class="paper-author">Shimin Chen, Qin Jin</div>
                                    <div class="paper-conf">VLDB 15</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Semantic Concept Annotation for User Generated Videos Using Soundtracks</div>
                                    <div class="paper-author">Qin Jin, Junwei Liang, Xixi He, Gang Yang, Jieping Xu, Xirong Li</div>
                                    <div class="paper-conf">ICMR 2015</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Speech Emotion Recognition With Acoustic And Lexical Features</div>
                                    <div class="paper-author">Qin Jin, Chengxin Li, Shizhe Chen, Huimin Wu</div>
                                    <div class="paper-conf">ICASSP 2015</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Detecting Semantic Concepts In Consumer Videos Using Audio</div>
                                    <div class="paper-author">Junwei Liang, Qin Jin, Xixi He, Gang Yang, Jieping Xu, Xirong Li</div>
                                    <div class="paper-conf">ICASSP 2015</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Does Product Recommendation Meet its Waterloo in Unexplored Categories? No, Price Comes to Help</div>
                                    <div class="paper-author">Jia Chen, Qin Jin, Shiwan Zhao, Shenghua Bao, Li Zhang, Zhong Su, Yong Yu</div>
                                    <div class="paper-conf">SIGIR 2014</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Semantic Concept Annotation of Consumer Videos at Frame-level Using Audio</div>
                                    <div class="paper-author">Junwei Liang, Qin Jin, Xixi He, Xirong Li, Gang Yang, Jieping Xu</div>
                                    <div class="paper-conf">Pacific-rim Conference on Multimedia (PCM) 2014</div>
                                </li>
                                
                                <li class="paper-list">
                                    <div class="paper-title">Speech Emotion Classification using Acoustic Features</div>
                                    <div class="paper-author">Shizhe Chen, Qin Jin, Xirong Li, Gang Yang, Jieping Xu</div>
                                    <div class="paper-conf">ISCSLP 2014</div>
                                </li>
                                
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <section data-w-id="a126a8e5-ac09-3e0e-ae62-4426c5ff4adf" class="footer">
            <div class="w-layout-blockcontainer main-container w-container">
                <div class="footer-master">
                    <div class="footer-bottom-tile">
                        <div data-w-id="06b62563-778f-f9d5-8004-6ace60d0bb0d" class="footer-bottom-wrap">
                            <div class="footer-last-block">
                                <!-- align: left -->
                                <div class="body-2" style="text-align: left;">
                                    <a href="https://www.ruc.edu.cn/" style="text-decoration: underline;"> </a><br>
                                    <!-- <a href="https://www.jin-qin.com/" style="text-decoration: underline;">Qin Jin</a> -->
                                </div>
                                <div class="body-2">Copyright &copy; 2024 AIM3 Lab</div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- <script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=66324ca3963cb173dcf869c8" type="text/javascript" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script> -->
        <script src="https://assets-global.website-files.com/66324ca3963cb173dcf869c8/js/webflow.c4947ca11.js" type="text/javascript"></script>
    </body>
</html>
